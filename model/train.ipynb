{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# Define your neural network architecture\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "# Custom dataset class\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(\"/lib/dataset.csv\")\n",
    "# Encode labels as 0 and 1\n",
    "data[\"label\"] = data[\"label\"].apply(lambda x: 0 if x == \"CG\" else 1)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[\"text\"], data[\"label\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert text data into numerical vectors using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "X_test = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# Define hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 128\n",
    "output_size = 1\n",
    "learning_rate = 3e-4\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "train_dataset = ReviewDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = BinaryClassifier(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/1011], Loss: 0.5157 Accuracy: 84.38%\n",
      "Epoch [1/10], Step [200/1011], Loss: 0.3271 Accuracy: 81.25%\n",
      "Epoch [1/10], Step [300/1011], Loss: 0.3232 Accuracy: 84.38%\n",
      "Epoch [1/10], Step [400/1011], Loss: 0.3612 Accuracy: 78.12%\n",
      "Epoch [1/10], Step [500/1011], Loss: 0.2004 Accuracy: 93.75%\n",
      "Epoch [1/10], Step [600/1011], Loss: 0.3322 Accuracy: 78.12%\n",
      "Epoch [1/10], Step [700/1011], Loss: 0.2139 Accuracy: 90.62%\n",
      "Epoch [1/10], Step [800/1011], Loss: 0.2145 Accuracy: 90.62%\n",
      "Epoch [1/10], Step [900/1011], Loss: 0.3016 Accuracy: 81.25%\n",
      "Epoch [1/10], Step [1000/1011], Loss: 0.0968 Accuracy: 96.88%\n",
      "Epoch [2/10], Step [100/1011], Loss: 0.2052 Accuracy: 90.62%\n",
      "Epoch [2/10], Step [200/1011], Loss: 0.1893 Accuracy: 96.88%\n",
      "Epoch [2/10], Step [300/1011], Loss: 0.1828 Accuracy: 87.50%\n",
      "Epoch [2/10], Step [400/1011], Loss: 0.6558 Accuracy: 78.12%\n",
      "Epoch [2/10], Step [500/1011], Loss: 0.1684 Accuracy: 93.75%\n",
      "Epoch [2/10], Step [600/1011], Loss: 0.1263 Accuracy: 100.00%\n",
      "Epoch [2/10], Step [700/1011], Loss: 0.0636 Accuracy: 100.00%\n",
      "Epoch [2/10], Step [800/1011], Loss: 0.0675 Accuracy: 96.88%\n",
      "Epoch [2/10], Step [900/1011], Loss: 0.1279 Accuracy: 90.62%\n",
      "Epoch [2/10], Step [1000/1011], Loss: 0.1990 Accuracy: 93.75%\n",
      "Epoch [3/10], Step [100/1011], Loss: 0.0633 Accuracy: 100.00%\n",
      "Epoch [3/10], Step [200/1011], Loss: 0.0948 Accuracy: 96.88%\n",
      "Epoch [3/10], Step [300/1011], Loss: 0.0812 Accuracy: 96.88%\n",
      "Epoch [3/10], Step [400/1011], Loss: 0.1028 Accuracy: 93.75%\n",
      "Epoch [3/10], Step [500/1011], Loss: 0.1881 Accuracy: 93.75%\n",
      "Epoch [3/10], Step [600/1011], Loss: 0.2304 Accuracy: 93.75%\n",
      "Epoch [3/10], Step [700/1011], Loss: 0.2053 Accuracy: 87.50%\n",
      "Epoch [3/10], Step [800/1011], Loss: 0.2265 Accuracy: 87.50%\n",
      "Epoch [3/10], Step [900/1011], Loss: 0.1191 Accuracy: 96.88%\n",
      "Epoch [3/10], Step [1000/1011], Loss: 0.1173 Accuracy: 96.88%\n",
      "Epoch [4/10], Step [100/1011], Loss: 0.0860 Accuracy: 96.88%\n",
      "Epoch [4/10], Step [200/1011], Loss: 0.0216 Accuracy: 100.00%\n",
      "Epoch [4/10], Step [300/1011], Loss: 0.0494 Accuracy: 96.88%\n",
      "Epoch [4/10], Step [400/1011], Loss: 0.1523 Accuracy: 90.62%\n",
      "Epoch [4/10], Step [500/1011], Loss: 0.1557 Accuracy: 96.88%\n",
      "Epoch [4/10], Step [600/1011], Loss: 0.0151 Accuracy: 100.00%\n",
      "Epoch [4/10], Step [700/1011], Loss: 0.1052 Accuracy: 96.88%\n",
      "Epoch [4/10], Step [800/1011], Loss: 0.2499 Accuracy: 87.50%\n",
      "Epoch [4/10], Step [900/1011], Loss: 0.1159 Accuracy: 96.88%\n",
      "Epoch [4/10], Step [1000/1011], Loss: 0.0763 Accuracy: 96.88%\n",
      "Epoch [5/10], Step [100/1011], Loss: 0.0878 Accuracy: 96.88%\n",
      "Epoch [5/10], Step [200/1011], Loss: 0.1672 Accuracy: 93.75%\n",
      "Epoch [5/10], Step [300/1011], Loss: 0.0317 Accuracy: 100.00%\n",
      "Epoch [5/10], Step [400/1011], Loss: 0.0922 Accuracy: 96.88%\n",
      "Epoch [5/10], Step [500/1011], Loss: 0.1318 Accuracy: 93.75%\n",
      "Epoch [5/10], Step [600/1011], Loss: 0.0695 Accuracy: 96.88%\n",
      "Epoch [5/10], Step [700/1011], Loss: 0.1440 Accuracy: 93.75%\n",
      "Epoch [5/10], Step [800/1011], Loss: 0.0575 Accuracy: 100.00%\n",
      "Epoch [5/10], Step [900/1011], Loss: 0.0464 Accuracy: 100.00%\n",
      "Epoch [5/10], Step [1000/1011], Loss: 0.2557 Accuracy: 87.50%\n",
      "Epoch [6/10], Step [100/1011], Loss: 0.0432 Accuracy: 100.00%\n",
      "Epoch [6/10], Step [200/1011], Loss: 0.0819 Accuracy: 93.75%\n",
      "Epoch [6/10], Step [300/1011], Loss: 0.1403 Accuracy: 96.88%\n",
      "Epoch [6/10], Step [400/1011], Loss: 0.1866 Accuracy: 93.75%\n",
      "Epoch [6/10], Step [500/1011], Loss: 0.0420 Accuracy: 100.00%\n",
      "Epoch [6/10], Step [600/1011], Loss: 0.0568 Accuracy: 100.00%\n",
      "Epoch [6/10], Step [700/1011], Loss: 0.0676 Accuracy: 96.88%\n",
      "Epoch [6/10], Step [800/1011], Loss: 0.1029 Accuracy: 93.75%\n",
      "Epoch [6/10], Step [900/1011], Loss: 0.0828 Accuracy: 96.88%\n",
      "Epoch [6/10], Step [1000/1011], Loss: 0.0586 Accuracy: 100.00%\n",
      "Epoch [7/10], Step [100/1011], Loss: 0.0465 Accuracy: 96.88%\n",
      "Epoch [7/10], Step [200/1011], Loss: 0.1213 Accuracy: 93.75%\n",
      "Epoch [7/10], Step [300/1011], Loss: 0.0437 Accuracy: 96.88%\n",
      "Epoch [7/10], Step [400/1011], Loss: 0.0386 Accuracy: 96.88%\n",
      "Epoch [7/10], Step [500/1011], Loss: 0.0729 Accuracy: 96.88%\n",
      "Epoch [7/10], Step [600/1011], Loss: 0.0278 Accuracy: 100.00%\n",
      "Epoch [7/10], Step [700/1011], Loss: 0.0457 Accuracy: 100.00%\n",
      "Epoch [7/10], Step [800/1011], Loss: 0.0476 Accuracy: 96.88%\n",
      "Epoch [7/10], Step [900/1011], Loss: 0.0540 Accuracy: 96.88%\n",
      "Epoch [7/10], Step [1000/1011], Loss: 0.2140 Accuracy: 93.75%\n",
      "Epoch [8/10], Step [100/1011], Loss: 0.0784 Accuracy: 100.00%\n",
      "Epoch [8/10], Step [200/1011], Loss: 0.0220 Accuracy: 96.88%\n",
      "Epoch [8/10], Step [300/1011], Loss: 0.1545 Accuracy: 96.88%\n",
      "Epoch [8/10], Step [400/1011], Loss: 0.0108 Accuracy: 100.00%\n",
      "Epoch [8/10], Step [500/1011], Loss: 0.0105 Accuracy: 100.00%\n",
      "Epoch [8/10], Step [600/1011], Loss: 0.0521 Accuracy: 100.00%\n",
      "Epoch [8/10], Step [700/1011], Loss: 0.0756 Accuracy: 96.88%\n",
      "Epoch [8/10], Step [800/1011], Loss: 0.0929 Accuracy: 93.75%\n",
      "Epoch [8/10], Step [900/1011], Loss: 0.0213 Accuracy: 100.00%\n",
      "Epoch [8/10], Step [1000/1011], Loss: 0.0929 Accuracy: 96.88%\n",
      "Epoch [9/10], Step [100/1011], Loss: 0.1426 Accuracy: 93.75%\n",
      "Epoch [9/10], Step [200/1011], Loss: 0.0255 Accuracy: 100.00%\n",
      "Epoch [9/10], Step [300/1011], Loss: 0.0245 Accuracy: 100.00%\n",
      "Epoch [9/10], Step [400/1011], Loss: 0.0221 Accuracy: 100.00%\n",
      "Epoch [9/10], Step [500/1011], Loss: 0.2504 Accuracy: 93.75%\n",
      "Epoch [9/10], Step [600/1011], Loss: 0.0251 Accuracy: 100.00%\n",
      "Epoch [9/10], Step [700/1011], Loss: 0.0143 Accuracy: 100.00%\n",
      "Epoch [9/10], Step [800/1011], Loss: 0.0628 Accuracy: 96.88%\n",
      "Epoch [9/10], Step [900/1011], Loss: 0.1000 Accuracy: 96.88%\n",
      "Epoch [9/10], Step [1000/1011], Loss: 0.0517 Accuracy: 96.88%\n",
      "Epoch [10/10], Step [100/1011], Loss: 0.2478 Accuracy: 90.62%\n",
      "Epoch [10/10], Step [200/1011], Loss: 0.0303 Accuracy: 100.00%\n",
      "Epoch [10/10], Step [300/1011], Loss: 0.0518 Accuracy: 100.00%\n",
      "Epoch [10/10], Step [400/1011], Loss: 0.0352 Accuracy: 100.00%\n",
      "Epoch [10/10], Step [500/1011], Loss: 0.1006 Accuracy: 96.88%\n",
      "Epoch [10/10], Step [600/1011], Loss: 0.1505 Accuracy: 93.75%\n",
      "Epoch [10/10], Step [700/1011], Loss: 0.0262 Accuracy: 100.00%\n",
      "Epoch [10/10], Step [800/1011], Loss: 0.0284 Accuracy: 100.00%\n",
      "Epoch [10/10], Step [900/1011], Loss: 0.1064 Accuracy: 90.62%\n",
      "Epoch [10/10], Step [1000/1011], Loss: 0.0029 Accuracy: 100.00%\n",
      "Accuracy: 89.65%\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.unsqueeze(1))\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            accuracy = (predicted == labels.unsqueeze(1)).float().mean()\n",
    "            print(\n",
    "                f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f} Accuracy: {accuracy.item()*100:.2f}%\"\n",
    "            )\n",
    "\n",
    "# Evaluation\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    predicted = (outputs > 0.5).float()\n",
    "    accuracy = (predicted == y_test_tensor.unsqueeze(1)).float().mean()\n",
    "    print(f\"Accuracy: {accuracy.item()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "torch.save(model.state_dict(), \"lib/model.pth\")\n",
    "with open('lib/vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
